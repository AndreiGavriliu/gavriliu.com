---
title: "Kubernetes Pod Affinity and Anti-Affinity: Scheduling With Style"
date: 2025-06-10T03:00:00+02:00
tags: ["kubernetes", "learn", "security"]

showShare: false
showReadTime: true
usePageBundles: true
toc: true
draft: false

# featureImage: 'header.png'
# featureImageAlt: 'by ChatGPT'
# featureImageCap: 'by ChatGPT'
thumbnail: 'header.png'
shareImage: 'header.png'

series: kubernetes
showRelatedInArticle:  true
showRelatedInSidebar: true
---

Pod Affinity and Anti-Affinity: The Kubernetes Seating Chart

Imagine Kubernetes as a big party where pods are the guests. Some guests (pods) want to sit together ‚Äî they‚Äôre best friends! Others‚Ä¶ well, they‚Äôd rather not be anywhere near each other. Kubernetes, being the polite party host it is, lets you manage these social dynamics using Pod Affinity and Pod Anti-Affinity.

‚∏ª

What Is Pod Affinity?

Pod Affinity lets you tell the scheduler: ‚ÄúHey, I want my pod to be placed on the same node (or zone) as another pod ‚Äî they get along.‚Äù

This is useful when pods benefit from being co-located, like sharing local storage or minimizing network latency.

Example: Web + Cache BFFs

apiVersion: v1
kind: Pod
metadata:
  name: web-app
spec:
  affinity:
    podAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchExpressions:
              - key: app
                operator: In
                values:
                  - cache
          topologyKey: "kubernetes.io/hostname"

This says:
	‚Ä¢	‚ÄúI want to be scheduled on a node with a pod labeled app: cache.‚Äù
	‚Ä¢	The topologyKey defines the domain ‚Äî here, it‚Äôs the same node.

‚∏ª

What Is Pod Anti-Affinity?

Pod Anti-Affinity is the opposite. It‚Äôs telling Kubernetes: ‚ÄúPlease don‚Äôt put me near that other pod.‚Äù

This is useful for high availability ‚Äî for instance, if you don‚Äôt want multiple replicas of the same app on one node.

Example: Avoiding Sibling Rivalry

apiVersion: v1
kind: Pod
metadata:
  name: backend
spec:
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchExpressions:
              - key: app
                operator: In
                values:
                  - backend
          topologyKey: "kubernetes.io/hostname"

Now the scheduler will make sure no two backend pods land on the same node.

‚∏ª

Required vs. Preferred

Kubernetes is pretty accommodating. With affinity and anti-affinity, you can say:
	‚Ä¢	requiredDuringSchedulingIgnoredDuringExecution: This must be met during scheduling. But if pods move later, Kubernetes won‚Äôt care.
	‚Ä¢	preferredDuringSchedulingIgnoredDuringExecution: A nice-to-have. ‚ÄúI‚Äôd like this‚Ä¶ but I won‚Äôt throw a tantrum if it doesn‚Äôt happen.‚Äù

Example: Soft Affinity

preferredDuringSchedulingIgnoredDuringExecution:
  - weight: 100
    podAffinityTerm:
      labelSelector:
        matchLabels:
          app: my-app
      topologyKey: "kubernetes.io/hostname"


‚∏ª

Topology Keys: Define the Neighborhood

The topologyKey decides how broadly to apply affinity:
	‚Ä¢	kubernetes.io/hostname: Same node
	‚Ä¢	topology.kubernetes.io/zone: Same zone (great for cloud setups)
	‚Ä¢	Custom keys: If you‚Äôre feeling fancy

‚∏ª

Use Cases

1. Keep Pods Together (Pod Affinity)
	‚Ä¢	Microservices with tight coupling
	‚Ä¢	Shared memory/cache
	‚Ä¢	Debugging/logging sidecars

2. Spread Pods Out (Pod Anti-Affinity)
	‚Ä¢	Replicas of a Deployment
	‚Ä¢	Fault tolerance
	‚Ä¢	Minimize noisy neighbors

‚∏ª

Gotchas and Good Practices
	‚Ä¢	Affinity only applies at scheduling time. Once the pod is scheduled, it can live happily even if affinity is later violated.
	‚Ä¢	Use anti-affinity for HA across nodes or zones.
	‚Ä¢	Don‚Äôt go wild with required rules unless you‚Äôre sure your cluster can satisfy them ‚Äî or pods may never get scheduled.
	‚Ä¢	MatchLabels vs. MatchExpressions: Use whichever suits your label setup.

‚∏ª

A Real-World Scenario

You‚Äôre running a distributed cache with multiple replicas:
	‚Ä¢	You want each replica on a different node (anti-affinity).
	‚Ä¢	You want your web pods close to a cache pod (affinity).

Apply both rules to your pod specs, and Kubernetes becomes your smart matchmaker.

‚∏ª

Wrapping Up

Pod Affinity and Anti-Affinity let you fine-tune where your workloads land in a Kubernetes cluster. They help with performance, reliability, and fault tolerance ‚Äî and sometimes just keeping the peace between grumpy pods.

Remember:
	‚Ä¢	Use required rules carefully
	‚Ä¢	preferred rules are great for flexibility
	‚Ä¢	Always test in staging before enforcing in prod

And yes, affinity can be‚Ä¶ magnetic.


‚∏ª

Got questions? Want to share a bizarre affinity use case? Drop a comment below or tag me on Mastodon at @gavriliu@fosstodon.org üß≤